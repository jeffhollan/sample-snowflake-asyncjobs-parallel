{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "|\"CURRENT_ACCOUNT()\"  |\n",
      "-----------------------\n",
      "|LAB23496             |\n",
      "-----------------------\n",
      "\n",
      "<snowflake.snowpark.session.Session: account=\"SFSENORTHAMERICA-JHOLLAN\", role=\"ACCOUNTADMIN\", database=\"TEMP\", schema=\"TEMP\", warehouse=\"XSMALL\">\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "session = Session.builder.config(\"connection_name\", \"demo\").getOrCreate()\n",
    "\n",
    "session.sql(\"SELECT CURRENT_ACCOUNT()\").show()\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<snowflake.snowpark.session.Session: account=\"SFSENORTHAMERICA-JHOLLAN\", role=\"ACCOUNTADMIN\", database=\"TEMP\", schema=\"TEMP\", warehouse=\"XSMALL\">\n"
     ]
    }
   ],
   "source": [
    "session.use_role(\"ACCOUNTADMIN\")\n",
    "\n",
    "session.sql(\"CREATE DATABASE IF NOT EXISTS TEMP\").collect()\n",
    "\n",
    "session.use_database(\"TEMP\")\n",
    "session.sql(\"CREATE SCHEMA IF NOT EXISTS TEMP\").collect()\n",
    "session.use_schema(\"TEMP\")\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=10000\n",
    "\n",
    "import modin.pandas as pd\n",
    "\n",
    "import snowflake.snowpark.modin.plugin\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for table1\n",
    "categories = np.random.choice(['A', 'B', 'C', 'D'], size=rows)\n",
    "products = np.random.choice(['X', 'Y', 'Z'], size=rows)\n",
    "regions = np.random.choice(['North', 'South', 'East', 'West'], size=rows)\n",
    "statuses = np.random.choice(['Active', 'Inactive'], size=rows)\n",
    "\n",
    "table1 = pd.DataFrame({\n",
    "    'category': categories,\n",
    "    'product': products,\n",
    "    'region': regions,\n",
    "    'status': statuses\n",
    "})\n",
    "\n",
    "# Generate random data for table2\n",
    "categories = np.random.choice(['A', 'B', 'C', 'D'], size=rows)\n",
    "products = np.random.choice(['X', 'Y', 'Z'], size=rows)\n",
    "regions = np.random.choice(['North', 'South', 'East', 'West'], size=rows)\n",
    "statuses = np.random.choice(['Active', 'Inactive'], size=rows)\n",
    "\n",
    "table2 = pd.DataFrame({\n",
    "    'category': categories,\n",
    "    'product': products,\n",
    "    'region': regions,\n",
    "    'status': statuses\n",
    "})\n",
    "\n",
    "snow_df1: snowflake.snowpark.DataFrame = pd.to_snowpark(table1, index_label='index')\n",
    "snow_df2: snowflake.snowpark.DataFrame = pd.to_snowpark(table2, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_df1.write.save_as_table(\"table1\", table_type=\"temp\", mode=\"overwrite\")\n",
    "snow_df2.write.save_as_table(\"table2\", table_type=\"temp\", mode=\"overwrite\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('\"index\"', LongType(), nullable=True), StructField('\"category\"', StringType(16777216), nullable=True), StructField('\"product\"', StringType(16777216), nullable=True), StructField('\"region\"', StringType(16777216), nullable=True), StructField('\"status\"', StringType(16777216), nullable=True)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_df1.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for jobs to complete..\n",
      "Job 1: False\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: False\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: False\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: False\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: False\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: False\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: False\n",
      "Job 3: False\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: False\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: False\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "Waiting for jobs to complete..\n",
      "Job 1: True\n",
      "Job 2: True\n",
      "Job 3: True\n",
      "Job 4: False\n",
      "All jobs completed!\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "# Join on category\n",
    "join_category = snow_df1.join(snow_df2, '\"category\"', \"inner\")\n",
    "\n",
    "# Join on product\n",
    "join_product = snow_df1.join(snow_df2, '\"product\"', \"inner\")\n",
    "\n",
    "# Join on region\n",
    "join_region = snow_df1.join(snow_df2, '\"region\"', \"inner\")\n",
    "\n",
    "# Join on status\n",
    "join_status = snow_df1.join(snow_df2, '\"status\"', \"inner\")\n",
    "\n",
    "job1 = join_category.write.save_as_table(\"join_category\", table_type=\"temp\", mode=\"overwrite\", block=False)\n",
    "job2 = join_product.write.save_as_table(\"join_product\", table_type=\"temp\", mode=\"overwrite\", block=False)\n",
    "job3 = join_region.write.save_as_table(\"join_region\", table_type=\"temp\", mode=\"overwrite\", block=False)\n",
    "job4 = join_status.write.save_as_table(\"join_status\", table_type=\"temp\", mode=\"overwrite\", block=False)\n",
    "\n",
    "while not job1.is_done() or not job2.is_done() or not job3.is_done() or not job4.is_done():\n",
    "    print(f\"Waiting for jobs to complete..\\nJob 1: {job1.is_done()}\\nJob 2: {job2.is_done()}\\nJob 3: {job3.is_done()}\\nJob 4: {job4.is_done()}\")\n",
    "    sleep(5)\n",
    "    pass\n",
    "\n",
    "print(\"All jobs completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1:  [Row(QUERY_ID='01b4f759-0002-7f74-003c-5f07006dee22', START_TIME=datetime.datetime(2024, 6, 12, 12, 37, 56, 263000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), END_TIME=datetime.datetime(2024, 6, 12, 12, 38, 42, 125000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), EXECUTION_STATUS='SUCCESS', EXECUTION_TIME_SECONDS=Decimal('45.680000'))]\n",
      "Job 2:  [Row(QUERY_ID='01b4f75a-0002-7f74-003c-5f07006dee26', START_TIME=datetime.datetime(2024, 6, 12, 12, 38, 1, 981000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), END_TIME=datetime.datetime(2024, 6, 12, 12, 39, 2, 234000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), EXECUTION_STATUS='SUCCESS', EXECUTION_TIME_SECONDS=Decimal('60.083000'))]\n",
      "Job 3:  [Row(QUERY_ID='01b4f75a-0002-7f75-003c-5f07006e2a92', START_TIME=datetime.datetime(2024, 6, 12, 12, 38, 6, 778000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), END_TIME=datetime.datetime(2024, 6, 12, 12, 38, 52, 266000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), EXECUTION_STATUS='SUCCESS', EXECUTION_TIME_SECONDS=Decimal('45.264000'))]\n",
      "Job 4:  [Row(QUERY_ID='01b4f75a-0002-7f75-003c-5f07006e2aa2', START_TIME=datetime.datetime(2024, 6, 12, 12, 38, 11, 827000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), END_TIME=datetime.datetime(2024, 6, 12, 12, 39, 39, 122000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), EXECUTION_STATUS='SUCCESS', EXECUTION_TIME_SECONDS=Decimal('87.100000'))]\n"
     ]
    }
   ],
   "source": [
    "def get_query_duration(session, query_id):\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            QUERY_ID,\n",
    "            START_TIME,\n",
    "            END_TIME,\n",
    "            EXECUTION_STATUS,\n",
    "            EXECUTION_TIME / 1000 AS EXECUTION_TIME_SECONDS -- Convert milliseconds to seconds\n",
    "        FROM \n",
    "            TABLE(INFORMATION_SCHEMA.QUERY_HISTORY())\n",
    "        WHERE \n",
    "            QUERY_ID = '{query_id}'\n",
    "    \"\"\"\n",
    "    result_df = session.sql(query)\n",
    "    result = result_df.collect()\n",
    "    return result\n",
    "\n",
    "print(\"Job 1: \", get_query_duration(session, job1.query_id))\n",
    "print(\"Job 2: \", get_query_duration(session, job2.query_id))\n",
    "print(\"Job 3: \", get_query_duration(session, job3.query_id))\n",
    "print(\"Job 4: \", get_query_duration(session, job4.query_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
